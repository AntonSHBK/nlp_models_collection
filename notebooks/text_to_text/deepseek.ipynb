{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импотрты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фиксируем random seed\n",
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('../../data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = DATA_PATH / Path('cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_INPUT = DATA_PATH / Path('input/')\n",
    "DATA_INPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_OUTPUT = DATA_PATH / Path('output/')\n",
    "DATA_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OFFLOAD_DIR = DATA_CACHE / Path('offload_weights/')\n",
    "OFFLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# Название модели\n",
    "MODEL_NAME = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=\"./cache\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=OFFLOAD_DIR,\n",
    "    cache_dir=DATA_CACHE\n",
    ")\n",
    "\n",
    "# Устанавливаем pad_token_id\n",
    "model.generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "\n",
    "print(\"✅ Модель успешно загружена!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def ask_model(user_input, max_tokens=512, temperature=0.1):\n",
    "    global chat_history  # Используем глобальную историю\n",
    "\n",
    "    # Добавляем сообщение пользователя в историю\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Создаем input tensor с учетом всей истории\n",
    "    input_tensor = tokenizer.apply_chat_template(\n",
    "        chat_history, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Генерация ответа\n",
    "    outputs = model.generate(\n",
    "        input_tensor.to(model.device),\n",
    "        max_new_tokens=max_tokens,\n",
    "        # temperature=temperature,\n",
    "        # top_p=0.9,\n",
    "        # repetition_penalty=1.1,\n",
    "    )\n",
    "\n",
    "    # Декодирование и обработка ответа\n",
    "    response = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Добавляем ответ модели в историю\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return response  # Возвращаем ответ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''\n",
    "Что это за документ? Определи по контексту:\n",
    "'Соглашение о расторжении\\nКонтракта № СТ-1383/22 от 31.01.2022 г.\\nна поставку наборов для катетеризации на 2022 год\\n\\nпос. Первомайское «30» декабря 2022 г.\\n\\nГосударственное бюджетное учреждение здравоохранения Ленинградской ласти «Рощинская\\nмежрайонная больница» (ГБУЗ ЛО «Рощинская МБ»), именуемое в дальнейшем «Заказчик», в лице\\nтлавного врача Казарова Эрнеста Эдуардовича, действующего на основании Устава, Общество с\\nограниченной ответственностью «Болюсмед» (ООО «Болюсмед»), именуемое в дальнейшем\\n«Поставщик», в лице генерального директора Беловой Христины Витальевны, действующего на\\nосновании Устава, с другой стороны, здесь и далее именуемые «Стороны», заключили настоящее\\nСоглашение к Контракту № СТ-1383/22 от 31.01.2022 г. о нижеследующем:\\n\\n1. Руководствуясь частью 8 статьи 95 ФЗ №44-ФЗ «О контрактной системе в сфере закупок товаров, работ,\\n‘услуг для обеспечения государственных и муниципальных нужд», пунктом 1 статьи 450 ГКРФ и пунктами\\n11.2, 11.3. Контракта № СТ-1383/22 от 31.01.2022 г, Стороны договорились расторгнуть Контракт\\n№ СТ-1383/22 от 31.01.2022 г. по соглашению сторон.\\n\\n2. Цена Контракта на момент расторжения соответствует стоимости фактически поставленного товара в\\nсумме 108 150,00 руб. (Сто восемь тысяч сто пятьдесят рублей 00 копеек), НДС не облагается.\\n\\n3. Оплата за фактически поставленный товар произведена Заказчиком в соответствии с условиями\\nКонтракта № СТ-1383/22 от 31.01.2022 г.\\n\\n4. Обязательства в оставшейся части на сумму 557 830,00 руб, (Пятьсот пятьдесят семь тысяч восемьсот\\nтридцать рублей 00 копеек) считаются прекращенными, поставке и оплате не подлежат.\\n\\n5. Все остальные условия Контракта № СТ-1383/22 от 31.01.2022 г. не затронутые настоящим\\nСоглашением, остаются неизменными и Стороны подтверждают по ним свои обязательства,\\n\\n6. Настоящее Соглашение составлено в двух подлинных экземплярах, по одному экземпляру для каждой из\\nСторон, имеющих одинаковую юридическую силу, и является неотъемлемой частью Контракта\\n№ СТ-1383/22 от 31.01.2022 г.\\n\\n7. Адреса, реквизиты и подписи сторон:\\n\\nЗаказчик: ГБУЗ ЛО «Рощинская МБ» Поставщик: ООО «Болюсмед»\\nЮридический и почтовый адрес: 188855, Юридический адрес: 194295, г Санкт-Петербург,\\nЛенинградская область, Выборгский район, ул. Ивана Фомина, д. 7, корп. 3, кв. 37\\n\\nп. Первомайское, ул. Ленина, д.54 «А» Почтовый адрес: 194064, г. Санкт-Петербург,\\nТел: 8(81378)68-509, е-тай: гто@тьох.ги пр. Раевского, д. 14, корп. 2, литер А, пом.8-Н,\\nИНН 4704047468 КПП 470401001 комн.4Б,5А,5Б (обособленное подразделение)\\nОГРН 1034700879212 Тел: (812) 703-50-98, е-тай: т@Боаетед п\\nБанковские реквизиты:\\n\\nОтделение Ленинградское Банка России// ИНН 7802664190 КПИ 780201001\\n\\nУФК по Ленинградской области г. Санкт-Петербур; ОГРН 1187847123947 от 27.04.2018\\n\\nКомитет финансов Ленинградской области Банковские реквизиты:\\n\\n(ГБУЗ ЛО «Рощинская МБ» л/с 2245620150) ПАО «Банк «Санкт-Петербург»\\n\\nБИК 014106101 БИК 044030790\\n\\nР/сч 03224643410000004500 Р/сч 40702810490700001210\\n\\nК/сч 40102810745370000006 К/сч 30101810900000000790\\n\\n_ Генеральный директор\\nОз«Болюсмед»\\nоо\\n\\n/ Х.В. Белова'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_model(content)\n",
    "print(f\"🤖 AI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''\n",
    "Составь список всех важных параметров\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_model(content)\n",
    "print(f\"🤖 AI: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
