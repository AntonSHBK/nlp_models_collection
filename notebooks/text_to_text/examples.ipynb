{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Загрузка переменных из файла .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_hf_token():\n",
    "    \"\"\"\n",
    "    Читает токен Hugging Face из переменной окружения HF_TOKEN.\n",
    "    Возвращает токен или вызывает исключение, если токен отсутствует.\n",
    "    \"\"\"\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")\n",
    "    if not hf_token:\n",
    "        raise ValueError(\"Токен Hugging Face (HF_TOKEN) не найден в переменных окружения. \"\n",
    "                         \"Добавьте его в файл .env или передайте явно.\")\n",
    "    return hf_token\n",
    "\n",
    "token = get_hf_token()\n",
    "print(\"Hugging Face токен успешно загружен:\", token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from models.base_model import TextGenerationModelLoader, ImageToTextModelLoader, VQAModelLoader\n",
    "\n",
    "\n",
    "class ImageCaptioningWithTranslation(ImageToTextModelLoader):\n",
    "    \"\"\"\n",
    "    Класс для описания изображений и перевода описания на русский язык.\n",
    "    Использует модель генерации описаний изображений и модель перевода текста.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_caption_model=\"Salesforce/blip-image-captioning-base\",\n",
    "                 translation_model=\"Helsinki-NLP/opus-mt-en-ru\",\n",
    "                 cache_dir=\"./data/cache\", use_gpu=True, hf_token=None):\n",
    "        # Инициализация модели для описания изображений\n",
    "        super().__init__(model_name=image_caption_model, cache_dir=cache_dir, use_gpu=use_gpu, hf_token=hf_token)\n",
    "\n",
    "        # Инициализация модели перевода текста\n",
    "        self.translation_pipeline = pipeline(\n",
    "            \"translation_en_to_ru\",\n",
    "            model=translation_model,\n",
    "            device=0 if use_gpu and torch.cuda.is_available() else -1,\n",
    "            use_auth_token=hf_token\n",
    "        )\n",
    "        print(f\"Модель перевода {translation_model} успешно загружена.\")\n",
    "\n",
    "    def describe_and_translate(self, image_path):\n",
    "        \"\"\"\n",
    "        Генерирует описание изображения и переводит его на русский язык.\n",
    "        \n",
    "        :param image_path: Путь к изображению.\n",
    "        :return: Описание изображения на русском языке.\n",
    "        \"\"\"\n",
    "        if not Path(image_path).exists():\n",
    "            raise FileNotFoundError(f\"Изображение не найдено: {image_path}\")\n",
    "\n",
    "        # Генерация описания изображения\n",
    "        description = self.generate_image_description(image_path)\n",
    "        print(f\"Сгенерированное описание на английском: {description}\")\n",
    "\n",
    "        # Перевод описания на русский язык\n",
    "        translation = self.translation_pipeline(description)[0][\"translation_text\"]\n",
    "        return description, translation\n",
    "\n",
    "    def display_image_with_caption(self, image_path, translation):\n",
    "        \"\"\"\n",
    "        Отображает изображение с русским описанием.\n",
    "        \n",
    "        :param image_path: Путь к изображению.\n",
    "        :param translation: Текст описания на русском языке.\n",
    "        \"\"\"\n",
    "        if not Path(image_path).exists():\n",
    "            raise FileNotFoundError(f\"Изображение не найдено: {image_path}\")\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Отображение изображения и перевода\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(translation, fontsize=14, wrap=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captioning_model = ImageCaptioningWithTranslation(\n",
    "    image_caption_model=\"Salesforce/blip-image-captioning-base\",\n",
    "    translation_model=\"Helsinki-NLP/opus-mt-en-ru\",\n",
    ")\n",
    "\n",
    "image_path = \"data/imgs/road.jpg\"\n",
    "\n",
    "# Генерация описания и перевода\n",
    "description, translated_caption = captioning_model.describe_and_translate(image_path)\n",
    "\n",
    "# Вывод текста перевода\n",
    "print(\"Сгенерированное описание на русском языке:\", translated_caption)\n",
    "\n",
    "# Отображение изображения с описанием\n",
    "captioning_model.display_image_with_caption(image_path, translated_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
