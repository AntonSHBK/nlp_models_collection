{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base_model import TextGenerationModelLoader, ImageToTextModelLoader, VQAModelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama\n",
    "\n",
    "\n",
    "- **[meta-llama/Llama-2-7B](https://huggingface.co/meta-llama/Llama-2-7B)**: Компактная версия, подходит для задач с ограниченными ресурсами.\n",
    "- **[meta-llama/Llama-2-13B](https://huggingface.co/meta-llama/Llama-2-13B)**: Средняя модель, обеспечивает баланс между производительностью и ресурсами.\n",
    "- **[meta-llama/Llama-2-70B](https://huggingface.co/meta-llama/Llama-2-70B)**: Модель с высокой точностью, требует значительных ресурсов.\n",
    "- **[meta-llama/Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)**: Обучена для задач инструкций, подходит для генерации текста и вопросов.\n",
    "- **[meta-llama/Llama-3.2-11B-Vision-Instruct](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct)**: Поддерживает мультимодальные задачи (текст + изображение)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование Text Generation Model\n",
    "print(\"Тестирование генерации текста:\")\n",
    "text_model_name = \"meta-llama/Llama-3.1-8B-Instruct\"  # Замените на актуальное имя модели\n",
    "text_model = TextGenerationModelLoader(model_name=text_model_name)\n",
    "\n",
    "text_prompt = \"Explain the main benefits of using Llama models for language tasks.\"\n",
    "generated_text = text_model.generate_text(text_prompt)\n",
    "\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text)\n",
    "\n",
    "# Тестирование Image to Text Model\n",
    "print(\"\\nТестирование генерации описания изображения:\")\n",
    "image_model_name = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"  # Замените на актуальное имя модели\n",
    "image_model = ImageToTextModelLoader(model_name=image_model_name)\n",
    "\n",
    "image_path = \"path_to_your_image.jpg\"  # Укажите путь к тестовому изображению\n",
    "image_description = image_model.generate_image_description(image_path)\n",
    "\n",
    "print(\"Описание изображения:\")\n",
    "print(image_description)\n",
    "\n",
    "# Тестирование VQA Model\n",
    "print(\"\\nТестирование визуально-вопросно-ответной модели (VQA):\")\n",
    "vqa_model_name = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"  # Замените на актуальное имя модели\n",
    "vqa_model = VQAModelLoader(model_name=vqa_model_name)\n",
    "\n",
    "vqa_question = \"What objects can you see in the image?\"\n",
    "vqa_answer = vqa_model.answer_question(image_path, vqa_question)\n",
    "\n",
    "print(\"Ответ на вопрос по изображению:\")\n",
    "print(vqa_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OFA\n",
    "\n",
    "- **[OFA-Tiny](https://huggingface.co/OFA-Sys/OFA-tiny)**: Легкая версия, оптимизированная для экономии памяти и скорости.\n",
    "- **[OFA-Medium](https://huggingface.co/OFA-Sys/OFA-medium)**: Сбалансированная модель для задач с ограниченными ресурсами.\n",
    "- **[OFA-Base](https://huggingface.co/OFA-Sys/OFA-base)**: Подходит для большинства приложений, обеспечивая хорошее соотношение производительности и ресурсов.\n",
    "- **[OFA-Large](https://huggingface.co/OFA-Sys/OFA-large)**: Повышенная производительность, подходит для более требовательных задач.\n",
    "- **[OFA-Huge](https://huggingface.co/OFA-Sys/OFA-huge)**: Модель с максимальной точностью и ресурсозатратностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование Text Generation Model с OFA\n",
    "print(\"Тестирование генерации текста:\")\n",
    "text_model_name = \"OFA-Sys/ofa-tiny\"  # Выберите модель OFA для генерации текста\n",
    "text_model = TextGenerationModelLoader(model_name=text_model_name)\n",
    "\n",
    "text_prompt = \"Explain the potential applications of the OFA model in AI research.\"\n",
    "generated_text = text_model.generate_text(text_prompt)\n",
    "\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text)\n",
    "\n",
    "# Тестирование Image to Text Model с OFA\n",
    "print(\"\\nТестирование генерации описания изображения:\")\n",
    "image_model_name = \"OFA-Sys/ofa-tiny\"  # Выберите модель OFA для задачи image-to-text\n",
    "image_model = ImageToTextModelLoader(model_name=image_model_name)\n",
    "\n",
    "image_path = \"path_to_your_image.jpg\"  # Укажите путь к тестовому изображению\n",
    "image_description = image_model.generate_image_description(image_path)\n",
    "\n",
    "print(\"Описание изображения:\")\n",
    "print(image_description)\n",
    "\n",
    "# Тестирование VQA Model с OFA\n",
    "print(\"\\nТестирование визуально-вопросно-ответной модели (VQA):\")\n",
    "vqa_model_name = \"OFA-Sys/ofa-tiny\"  # Выберите модель OFA для задачи VQA\n",
    "vqa_model = VQAModelLoader(model_name=vqa_model_name)\n",
    "\n",
    "vqa_question = \"What objects are visible in the image?\"\n",
    "vqa_answer = vqa_model.answer_question(image_path, vqa_question)\n",
    "\n",
    "print(\"Ответ на вопрос по изображению:\")\n",
    "print(vqa_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLIP\n",
    "\n",
    "- **[BLIP-base](https://huggingface.co/Salesforce/blip-image-captioning-base)**: Базовая версия модели для описания изображений.\n",
    "- **[BLIP-large](https://huggingface.co/Salesforce/blip-image-captioning-large)**: Более мощная версия для описания изображений.\n",
    "- **[BLIP-VQA-base](https://huggingface.co/Salesforce/blip-vqa-base)**: Базовая версия модели для визуально-вопросно-ответных задач.\n",
    "- **[BLIP-VQA-large](https://huggingface.co/Salesforce/blip-vqa-large)**: Улучшенная версия модели для VQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование Image to Text Model с BLIP\n",
    "print(\"Тестирование генерации описания изображения:\")\n",
    "image_model_name = \"Salesforce/blip-image-captioning-base\"  # Выберите модель BLIP для задачи image-to-text\n",
    "image_model = ImageToTextModelLoader(model_name=image_model_name)\n",
    "\n",
    "image_path = \"path_to_your_image.jpg\"  # Укажите путь к тестовому изображению\n",
    "image_description = image_model.generate_image_description(image_path)\n",
    "\n",
    "print(\"Описание изображения:\")\n",
    "print(image_description)\n",
    "\n",
    "# Тестирование VQA Model с BLIP\n",
    "print(\"\\nТестирование визуально-вопросно-ответной модели (VQA):\")\n",
    "vqa_model_name = \"Salesforce/blip-vqa-base\"  # Выберите модель BLIP для задачи VQA\n",
    "vqa_model = VQAModelLoader(model_name=vqa_model_name)\n",
    "\n",
    "vqa_question = \"What is happening in the image?\"\n",
    "vqa_answer = vqa_model.answer_question(image_path, vqa_question)\n",
    "\n",
    "print(\"Ответ на вопрос по изображению:\")\n",
    "print(vqa_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIT\n",
    "\n",
    "- **[GIT-base](https://huggingface.co/microsoft/git-base)**: Базовая версия модели для генерации описаний изображений.\n",
    "- **[GIT-large](https://huggingface.co/microsoft/git-large)**: Улучшенная версия модели для генерации описаний изображений с более высоким качеством."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование Image to Text Model с GIT\n",
    "print(\"Тестирование генерации описания изображения с GIT:\")\n",
    "image_model_name = \"microsoft/git-base\"  # Выберите модель GIT для задачи image-to-text\n",
    "image_model = ImageToTextModelLoader(model_name=image_model_name)\n",
    "\n",
    "image_path = \"path_to_your_image.jpg\"  # Укажите путь к тестовому изображению\n",
    "image_description = image_model.generate_image_description(image_path)\n",
    "\n",
    "print(\"Описание изображения:\")\n",
    "print(image_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5\n",
    "\n",
    "- **[T5-small](https://huggingface.co/t5-small)**: Легкая версия модели T5, оптимизированная для быстрого выполнения.\n",
    "- **[T5-base](https://huggingface.co/t5-base)**: Базовая версия T5 с более высокой точностью, чем T5-small.\n",
    "- **[T5-large](https://huggingface.co/t5-large)**: Улучшенная версия модели для более точной генерации текста.\n",
    "- **[T5-3B](https://huggingface.co/t5-3b)**: Версия с 3 миллиардами параметров, которая обеспечивает высокий уровень производительности.\n",
    "- **[T5-11B](https://huggingface.co/t5-11b)**: Наиболее мощная версия модели T5 с 11 миллиардами параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование генерации текста с T5\n",
    "print(\"Тестирование генерации текста с T5:\")\n",
    "text_model_name = \"t5-base\"  # Выберите модель T5 для задачи генерации текста\n",
    "text_model = TextGenerationModelLoader(model_name=text_model_name)\n",
    "\n",
    "prompt = \"translate English to French: The weather is nice today.\"  # Пример запроса для перевода\n",
    "generated_text = text_model.generate_text(prompt)\n",
    "\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-based generators\n",
    "\n",
    "Хотя **BERT** изначально не предназначен для генерации текста, существуют его версии, адаптированные для таких задач, как суммаризация и генерация ответов. Эти модели основаны на BERT и других трансформерах, модифицированных для генерации текста:\n",
    "\n",
    "- **[BERT2BERT](https://huggingface.co/google/bert2bert_L-24_wmt_de_en)**: Модель для генерации текстов и перевода, основанная на архитектуре BERT для задач перевода.\n",
    "- **[CTRL](https://huggingface.co/salesforce/ctrl)**: Модель на основе BERT, предназначенная для более контролируемой генерации текста.\n",
    "- **[DistilBERT for Summarization](https://huggingface.co/sshleifer/distilbart-cnn-12-6)**: Легкая модель для задачи суммаризации, основанная на BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование генерации текста с BERT-based моделью\n",
    "print(\"Тестирование генерации текста с BERT-based генератором:\")\n",
    "bert_model_name = \"google/bert2bert_L-24_wmt_de_en\"  # Выберите BERT-based модель, например, для перевода\n",
    "text_model = TextGenerationModelLoader(model_name=bert_model_name)\n",
    "\n",
    "prompt = \"translate English to German: The machine learning model is highly accurate.\"  # Пример запроса для перевода\n",
    "generated_text = text_model.generate_text(prompt)\n",
    "\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
